# Code Execution


## Quality Check

quality_check:
  score: 8
  issues:
    - type: "Accuracy"
      description: "The documentation generally describes code execution concepts accurately, but omits some details regarding error handling, security boundaries, and how LLM-generated code is actually executed (e.g., mechanisms for code injection prevention)."
      severity: "medium"
      suggestion: "Add more precise information about security measures (e.g., sandboxing specifics, code validation steps) and clarify how LLM-generated code is securely executed."
    - type: "Clarity"
      description: "A few advanced terms (e.g., 'polyglot backends', 'session state') are introduced without definition. Some sentences are dense, which could challenge less-experienced readers."
      severity: "low"
      suggestion: "Add brief definitions or links for advanced terms and consider splitting longer sentences for readability."
    - type: "Completeness"
      description: "Error handling in multi-agent workflows, tool deregistration, and more complex execution flows (e.g., asynchronous execution, streaming outputs) are not addressed."
      severity: "medium"
      suggestion: "Expand the section to mention how errors are propagated in group chats, how to deregister or update tools, and touch on advanced execution patterns."
    - type: "Code Example Quality"
      description: "The code examples are clear and well-labeled but could benefit from showing error handling and output in more than just the first example. The last example lacks output demonstration and does not clarify how the agents process the message."
      severity: "low"
      suggestion: "Add comments or output statements to all examples, and briefly explain expected outputs or agent behaviors."
    - type: "Best Practices Coverage"
      description: "Best practices are solid but could benefit from prioritization and explicit mention of version control or testing for tools."
      severity: "low"
      suggestion: "Highlight the most critical best practices (e.g., security first), and suggest versioning/testing for tools."
  strengths:
    - "Accurately describes the architecture and abstractions (Tool, Toolkit, ConversableAgent, execution backends) for code execution."
    - "Provides practical, clear code examples that illustrate core usage patterns."
  recommendations:
    - "Expand on security practices and clarify how LLM-generated code is evaluated and isolated."
    - "Broaden the section to cover more advanced scenarios (error propagation, async execution, tool deregistration) and provide a glossary for advanced terms."


## Content

content:
  overview: |
    Code execution in advanced agent frameworks empowers agents to go beyond natural language reasoning by actually running code, invoking tools, and managing execution environments. This capability allows agents to solve tasks programmatically, execute user-defined or system-provided functions ("tools"), and interact safely with the outside world. Execution environments can be locally sandboxed, remote, or even cloud-based, and must be managed to ensure security, reproducibility, and efficiency.
  explanation: |
    In an agentic system, "code execution" refers to the agent's ability to run code—either generated by an LLM or pre-registered as a callable tool—during a conversation or workflow. This is achieved via abstractions that wrap functions as "Tools," which are then registered with agent instances (like `ConversableAgent`). When a user or another agent issues a command or request, the agent can resolve the request to a specific tool, call it with the appropriate arguments, and return the result in the ongoing conversation.

    The execution environment determines where and how this code runs. By default, Python functions/tools run in the agent’s local environment, but advanced settings may use containerized, remote, or polyglot backends to isolate or scale execution. Managing execution environments involves controlling resource usage, handling security concerns (e.g., code injection risks), and tracking execution context (such as variable scope, working directory, or even session state).

    Key abstractions and patterns:
      - **ConversableAgent** is the core agent type, managing chat, tool registration, and message dispatch.
      - **Tool** and **Toolkit** wrap and organize executable functions, supporting both LLM-initiated and direct execution.
      - Tools can be registered for "execution" (actual code run), "propose" (LLM can suggest the tool), or both.
      - Agents may support custom execution backends or context (e.g., Jupyter, subprocess, remote API).
      - Group settings (multi-agent chats) may require careful environment management to avoid conflicts or resource leaks.
      - LLM-generated code execution is supported via secure evaluation interfaces, and often includes output/error capture.
  examples:
    - title: "Registering and Executing a Tool"
      description: |
        Register a Python function as a tool with an agent, then execute it via agent interaction.
      code: |
        from autogen import ConversableAgent
        from autogen.tools import tool

        # Define a tool (function) to add two numbers
        @tool(name="add", description="Add two numbers")
        def add(a: int, b: int) -> int:
            return a + b

        # Create an agent and register the tool
        agent = ConversableAgent(
            name="assistant",
            system_message="You can execute tools.",
            llm_config={...}
        )
        agent.register_for_execution()(add)

        # Simulate code execution in response to a message
        result = agent.execute_tool("add", a=2, b=3)
        print(result)  # Output: 5

    - title: "Tool Registration for LLM and Execution"
      description: |
        Register a tool for both LLM function-calling and direct execution, allowing agents to use it in conversations or directly.
      code: |
        @tool(name="multiply", description="Multiply two numbers")
        def multiply(a: int, b: int) -> int:
            return a * b

        agent.register_tool(multiply)  # Registers for both propose and execute

    - title: "Custom Execution Environment (Jupyter Backend)"
      description: |
        Configure an agent to execute code snippets in a Jupyter kernel (e.g., for Python code execution isolation).
      code: |
        from autogen import ConversableAgent
        from autogen.execution.jupyter import JupyterExecutionBackend

        agent = ConversableAgent(
            name="notebook_agent",
            system_message="You can execute Python code in a Jupyter kernel.",
            llm_config={...},
            execution_backend=JupyterExecutionBackend()
        )

        code = "print(2 + 2)"
        output = agent.execute_code(code)
        print(output)  # Output: 4

    - title: "Group Chat: Managing Tool Execution in Multi-Agent Workflows"
      description: |
        Set up a group chat where agents can execute code/tools in a coordinated way, ensuring that each agent's execution context is managed.
      code: |
        from autogen import GroupChat, GroupChatManager, ConversableAgent
        from autogen.tools import tool

        @tool(name="increment", description="Increment a number")
        def increment(x: int) -> int:
            return x + 1

        agent1 = ConversableAgent("agent1")
        agent2 = ConversableAgent("agent2")
        agent1.register_for_execution()(increment)
        agent2.register_for_execution()(increment)

        groupchat = GroupChat([agent1, agent2])
        manager = GroupChatManager(groupchat)
        agent1.initiate_chat(manager, message="Increment 5")

  best_practices:
    - "Always register tools with accurate type hints and descriptions for reliable code execution and LLM integration."
    - "Use decorators (e.g., @tool) for registering functions as tools; avoid manual Tool object creation unless necessary."
    - "Isolate code execution if running untrusted or user-generated code (use Jupyter, subprocess, or containers)."
    - "Monitor resource usage and handle errors gracefully; capture exceptions and return informative error messages."
    - "Register all required tools before starting a chat or workflow to ensure the agent can access them."
    - "Explicitly manage agent execution context in group chats to avoid state leaks or conflicts."
    - "Avoid registering tools with overlapping names to prevent ambiguity in function calls."
    - "Audit code execution permissions in production environments for security."

  related_concepts:
    - name: "Tool and Toolkit"
      description: "Tools encapsulate executable functions, and toolkits organize them; code execution relies on these abstractions for structured, safe invocation."
    - name: "ConversableAgent"
      description: "The primary agent class that manages tool registration, execution, and message flow, enabling code execution in conversations."
    - name: "LLMConfig"
      description: "LLMConfig determines which language model to use for code generation or tool call proposal; execution may be directly or LLM-initiated."
    - name: "GroupChat and GroupChatManager"
      description: "Multi-agent workflows often require careful code execution management to ensure each agent's context and tools are isolated and coordinated."
    - name: "Execution Backend"
      description: "Custom backends (e.g., Jupyter, subprocess) allow for sandboxed or language-specific code execution beyond the default Python environment."
    - name: "Tool Interoperability"
      description: "Supports running tools imported from other ecosystems (like LangChain), expanding the agent's execution possibilities."
    - name: "Security and Sandboxing"
      description: "Code execution introduces security risks; use sandboxing (containers, restricted kernels) and review generated code for safety."